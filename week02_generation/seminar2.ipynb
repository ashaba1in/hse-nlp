{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seminar 2. Text generation\n",
    "\n",
    "\n",
    "#### Agenda\n",
    "\n",
    "1. Tokenization\n",
    "2. RNN\n",
    "3. Generation quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echimbulatov/miniconda3/envs/cosmos/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tokenizers import Tokenizer, models, trainers\n",
    "from tokenizers.normalizers import Lowercase\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from tokenizers.decoders import WordPiece as WordPieceDecoder\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Tokenization is the process of breaking text into substrings (tokens). Tokenization is primarily used to reduce the size of the vocabulary. During tokenization, we want all tokens to be as representative as possible. Thus, we balance vocabulary size with token representativeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, models\n",
    "\n",
    "tokenizer = Tokenizer(models.BPE())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization includes several components:\n",
    "\n",
    "1. **Normalization** - preliminary text cleaning (converting to lowercase, replacing Unicode characters with ASCII, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello how are u?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers import normalizers\n",
    "from tokenizers.normalizers import NFD, StripAccents, Lowercase, Strip\n",
    "\n",
    "normalizer = normalizers.Sequence([NFD(), StripAccents(), Lowercase(), Strip()])\n",
    "normalizer.normalize_str(\" Héllò hôw are ü?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.normalizer = normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Pre-tokenization** is the process of breaking text into smaller fragments that set an upper bound on what the tokens will be in the tokenization. Typically, pre-tokenization breaks the text into words. The resulting tokens will then be parts of these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', (0, 5)),\n",
       " ('!', (5, 6)),\n",
       " ('How', (7, 10)),\n",
       " ('are', (11, 14)),\n",
       " ('you', (15, 18)),\n",
       " ('?', (18, 19)),\n",
       " ('I', (20, 21)),\n",
       " (\"'\", (21, 22)),\n",
       " ('m', (22, 23)),\n",
       " ('fine', (24, 28)),\n",
       " (',', (28, 29)),\n",
       " ('thank', (30, 35)),\n",
       " ('you', (36, 39)),\n",
       " ('.', (39, 40))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "pre_tokenizer = Whitespace()\n",
    "pre_tokenizer.pre_tokenize_str(\"Hello! How are you? I'm fine, thank you.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the string \"I'm\" is split into [\"I\", \"'\", \"m\"]. This may not be a good thing, given that \"'m\" is the same as \"am\". For a more \"correct\" split, you can use rule-based pre-tokenization. The most popular tools for this are `spaCy` and `Moses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Model** is the main part of tokenization. The model must be trained on a text corpus to obtain a dictionary suitable for specific data. It is applied to the result of pre-tokenization. And its task is to break \"words\" into smaller components according to the learned rules.\n",
    "\n",
    "The most common types of models are `BPE`, `WordPiece`, `Unigram`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Byte-Pair Encoding (BPE)\n",
    "\n",
    "__Training Algorithm:__\n",
    "\n",
    "1. Count the number of occurrences of each word in the corpus.\n",
    "2. Create a dictionary of tokens, which currently consists of all unique characters.\n",
    "3. Find the pair of tokens that appear together most often. Concatenate them into a token and add it to the dictionary.\n",
    "4. Repeat step 3 until the dictionary reaches the desired size.\n",
    "\n",
    "\n",
    "__Example:__\n",
    "\n",
    "Corpus of words with occurrences: (`(\"hug\", 2)`, `(\"pug\", 1)`, `(\"pun\", 4)`, `(\"bun\", 3)`, `(\"hugs\", 1)`)   \n",
    "Maximum vocabulary size – __9__.\n",
    "\n",
    "__Step 1.__    \n",
    "Vocabulary: [`\"b\"`, `\"g\"`, `\"h\"`, `\"n\"`, `\"p\"`, `\"s\"`, `\"u\"`], size: __7__.   \n",
    "Corpus: [`(\"h\" \"u\" \"g\", 3)`, `(\"p\" \"u\" \"g\", 1)`, `(\"p\" \"u\" \"n\", 3)`, `(\"b\" \"u\" \"n\", 3)`, `(\"h\" \"u\" \"g\" \"s\", 1)`]\n",
    "\n",
    "The most common pair is (`\"u\" \"n\"`) – 6 times. We add it to the vocabulary and update the corpus.\n",
    "\n",
    "__Step 2.__    \n",
    "Vocabulary: [`\"b\"`, `\"g\"`, `\"h\"`, `\"n\"`, `\"p\"`, `\"s\"`, `\"u\"`, `\"un\"`], size: __8__.   \n",
    "Corpus: [`(\"h\" \"u\" \"g\", 3)`, `(\"p\" \"u\" \"g\", 1)`, `(\"p\" \"un\", 3)`, `(\"b\" \"un\", 3)`, `(\"h\" \"u\" \"g\" \"s\", 1)`]\n",
    "\n",
    "The most common pair is (`\"u\" \"g\"`) – 5 times. We add it to the vocabulary and update the corpus.\n",
    "\n",
    "__Step 3.__    \n",
    "Vocabulary: [`\"b\"`, `\"g\"`, `\"h\"`, `\"n\"`, `\"p\"`, `\"s\"`, `\"u\"`, `\"un\"`, `\"ug\"`], size: __9__.    \n",
    "Corpus: [`(\"h\" \"ug\", 3)`, `(\"p\" \"ug\", 1)`, `(\"p\" \"un\", 3)`, `(\"b\" \"un\", 3)`, `(\"h\" \"ug\" \"s\", 1)`]\n",
    "\n",
    "\n",
    "__Tokenization Process:__\n",
    "\n",
    "1. Normalization\n",
    "1. Pre-tokenization\n",
    "1. Splitting words into individual characters\n",
    "1. Applying merging rules (in the order they appear in the dictionary) to the split words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Byte-level BPE\n",
    "\n",
    "If you're training a very large model on the entire internet, you might encounter a situation where the test set contains tokens that aren't in the dictionary (for example, emojis). In this case, you'll have to change the tokens to UNK, losing this information.\n",
    "\n",
    "GPT-2 and RoBERTa tokenizers (which are quite similar) have a clever way to solve this problem: they treat words as bytes rather than Unicode characters. This way, the base dictionary is small (256), but all the characters you can think of are still included and won't be converted into an unknown token. This trick is called byte-level BPE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WordPiece\n",
    "\n",
    "WordPiece works exactly like BPE, with the exception of selecting tokens for merging. BPE doesn't consider the frequency of each token individually. WordPiece corrects this by introducing a score that evaluates the necessity of merging two tokens.\n",
    "\n",
    "$$\n",
    "\\operatorname{score}=\\frac{\\operatorname{freq of pair}}{\\operatorname{freq of first element}\\times \\operatorname{freq of second element}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import trainers\n",
    "\n",
    "texts = [\n",
    "    \"An infinite number of mathematicians walk into a bar.\",\n",
    "    \"The first one orders one beer. The second one - half a pint, the third one - a quarter.\",\n",
    "    \"– Hey, hey, hey, stop! Here are two pints for everyone, and leave me alone!\"\n",
    "]\n",
    "\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=128, min_frequency=1,\n",
    "    special_tokens=['[BOS]', '[EOS]'],\n",
    "    continuing_subword_prefix='##',  # add special prefix to allow detokenization\n",
    ")\n",
    "tokenizer.train_from_iterator(texts, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['an', 'infi', '##ni', '##te', 'numb', '##er', 'of', 'mathem', '##atic', '##ian', '##s', 'wal', '##k', 'into', 'a', 'bar', '.']\n",
      "Ids: [58, 119, 96, 92, 123, 50, 81, 122, 108, 99, 43, 87, 48, 120, 6, 69, 5]\n"
     ]
    }
   ],
   "source": [
    "tokenized = tokenizer.encode(\"An infinite number of mathematicians walk into a bar.\")\n",
    "print('Tokens:', tokenized.tokens)\n",
    "print('Ids:', tokenized.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. __Post-processing__ is the final step of tokenization. It's necessary to modify the tokenized text in any way, for example, to add beginning and end tokens to the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.processors import TemplateProcessing\n",
    "\n",
    "post_processor = TemplateProcessing(\n",
    "    single=\"[BOS] $A [EOS]\",\n",
    "    special_tokens=[(\"[BOS]\", 1), (\"[EOS]\", 2)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['[BOS]', 'an', 'infi', '##ni', '##te', 'numb', '##er', 'of', 'mathem', '##atic', '##ian', '##s', 'wal', '##k', 'into', 'a', 'bar', '.', '[EOS]']\n",
      "Ids: [1, 58, 119, 96, 92, 123, 50, 81, 122, 108, 99, 43, 87, 48, 120, 6, 69, 5, 2]\n"
     ]
    }
   ],
   "source": [
    "processed = post_processor.process(tokenized)\n",
    "print('Tokens:', processed.tokens)\n",
    "print('Ids:', processed.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decoder = WordPieceDecoder(prefix='##', cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an infinite number of mathematicians walk into a bar.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echimbulatov/miniconda3/envs/cosmos/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk('/home/amshabalin/data/rocstories')\n",
    "dataset[\"train\"] = dataset[\"train\"][:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = np.array(dataset['train']['target'])\n",
    "test_texts = np.array(dataset['test']['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_texts(texts):\n",
    "    for t in texts:\n",
    "        print(t, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelly was at home, trying to sleep. Suddenly, she heard footsteps in her kitchen. She grabbed a gun and stood at the top of the stairs. She warned whoever it was that she was armed. She heard them run out of the house and then called police.\n",
      "\n",
      "I bought a 1969 Mercury Montego with a loose front seat. The seat was loose because the car's floor had rusted through. I removed the seat and repaired the floor with pieces of sheet metal. My repair held the seat firmly in place after I reinstalled it. The car then successfully passed the safety inspection.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idxs = [5, 9]\n",
    "print_texts(train_texts[idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_tokenizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized\n",
      "['[BOS]', 'k', 'e', 'l', 'l', 'y', ' ', 'w', 'a', 's', ' ', 'a', 't', ' ', 'h', 'o', 'm', 'e', ',', ' ', 't', 'r', 'y', 'i', 'n', 'g', ' ', 't', 'o', ' ', 's', 'l', 'e', 'e', 'p', '.', ' ', 's', 'u', 'd', 'd', 'e', 'n', 'l', 'y', ',', ' ', 's', 'h', 'e', ' ', 'h', 'e', 'a', 'r', 'd', ' ', 'f', 'o', 'o', 't', 's', 't', 'e', 'p', 's', ' ', 'i', 'n', ' ', 'h', 'e', 'r', ' ', 'k', 'i', 't', 'c', 'h', 'e', 'n', '.', ' ', 's', 'h', 'e', ' ', 'g', 'r', 'a', 'b', 'b', 'e', 'd', ' ', 'a', ' ', 'g', 'u', 'n', ' ', 'a', 'n', 'd', ' ', 's', 't', 'o', 'o', 'd', ' ', 'a', 't', ' ', 't', 'h', 'e', ' ', 't', 'o', 'p', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 's', 't', 'a', 'i', 'r', 's', '.', ' ', 's', 'h', 'e', ' ', 'w', 'a', 'r', 'n', 'e', 'd', ' ', 'w', 'h', 'o', 'e', 'v', 'e', 'r', ' ', 'i', 't', ' ', 'w', 'a', 's', ' ', 't', 'h', 'a', 't', ' ', 's', 'h', 'e', ' ', 'w', 'a', 's', ' ', 'a', 'r', 'm', 'e', 'd', '.', ' ', 's', 'h', 'e', ' ', 'h', 'e', 'a', 'r', 'd', ' ', 't', 'h', 'e', 'm', ' ', 'r', 'u', 'n', ' ', 'o', 'u', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'h', 'o', 'u', 's', 'e', ' ', 'a', 'n', 'd', ' ', 't', 'h', 'e', 'n', ' ', 'c', 'a', 'l', 'l', 'e', 'd', ' ', 'p', 'o', 'l', 'i', 'c', 'e', '.', '[EOS]']\n",
      "\n",
      "['[BOS]', 'i', ' ', 'b', 'o', 'u', 'g', 'h', 't', ' ', 'a', ' ', '1', '9', '6', '9', ' ', 'm', 'e', 'r', 'c', 'u', 'r', 'y', ' ', 'm', 'o', 'n', 't', 'e', 'g', 'o', ' ', 'w', 'i', 't', 'h', ' ', 'a', ' ', 'l', 'o', 'o', 's', 'e', ' ', 'f', 'r', 'o', 'n', 't', ' ', 's', 'e', 'a', 't', '.', ' ', 't', 'h', 'e', ' ', 's', 'e', 'a', 't', ' ', 'w', 'a', 's', ' ', 'l', 'o', 'o', 's', 'e', ' ', 'b', 'e', 'c', 'a', 'u', 's', 'e', ' ', 't', 'h', 'e', ' ', 'c', 'a', 'r', \"'\", 's', ' ', 'f', 'l', 'o', 'o', 'r', ' ', 'h', 'a', 'd', ' ', 'r', 'u', 's', 't', 'e', 'd', ' ', 't', 'h', 'r', 'o', 'u', 'g', 'h', '.', ' ', 'i', ' ', 'r', 'e', 'm', 'o', 'v', 'e', 'd', ' ', 't', 'h', 'e', ' ', 's', 'e', 'a', 't', ' ', 'a', 'n', 'd', ' ', 'r', 'e', 'p', 'a', 'i', 'r', 'e', 'd', ' ', 't', 'h', 'e', ' ', 'f', 'l', 'o', 'o', 'r', ' ', 'w', 'i', 't', 'h', ' ', 'p', 'i', 'e', 'c', 'e', 's', ' ', 'o', 'f', ' ', 's', 'h', 'e', 'e', 't', ' ', 'm', 'e', 't', 'a', 'l', '.', ' ', 'm', 'y', ' ', 'r', 'e', 'p', 'a', 'i', 'r', ' ', 'h', 'e', 'l', 'd', ' ', 't', 'h', 'e', ' ', 's', 'e', 'a', 't', ' ', 'f', 'i', 'r', 'm', 'l', 'y', ' ', 'i', 'n', ' ', 'p', 'l', 'a', 'c', 'e', ' ', 'a', 'f', 't', 'e', 'r', ' ', 'i', ' ', 'r', 'e', 'i', 'n', 's', 't', 'a', 'l', 'l', 'e', 'd', ' ', 'i', 't', '.', ' ', 't', 'h', 'e', ' ', 'c', 'a', 'r', ' ', 't', 'h', 'e', 'n', ' ', 's', 'u', 'c', 'c', 'e', 's', 's', 'f', 'u', 'l', 'l', 'y', ' ', 'p', 'a', 's', 's', 'e', 'd', ' ', 't', 'h', 'e', ' ', 's', 'a', 'f', 'e', 't', 'y', ' ', 'i', 'n', 's', 'p', 'e', 'c', 't', 'i', 'o', 'n', '.', '[EOS]']\n",
      "\n",
      "Detokenized\n",
      "kelly was at home, trying to sleep. suddenly, she heard footsteps in her kitchen. she grabbed a gun and stood at the top of the stairs. she warned whoever it was that she was armed. she heard them run out of the house and then called police.\n",
      "\n",
      "i bought a 1969 mercury montego with a loose front seat. the seat was loose because the car's floor had rusted through. i removed the seat and repaired the floor with pieces of sheet metal. my repair held the seat firmly in place after i reinstalled it. the car then successfully passed the safety inspection.\n",
      "\n",
      "Vocab size: 82\n"
     ]
    }
   ],
   "source": [
    "tok = CharacterTokenizer(train_texts)\n",
    "\n",
    "tokenized = tok.encode(train_texts[idxs])\n",
    "print('Tokenized')\n",
    "print_texts(tokenized['tokens'])\n",
    "print('Detokenized')\n",
    "print_texts(tok.decode(tokenized['input_ids']))\n",
    "\n",
    "print(f'Vocab size: {len(tok.token2id)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAADcCAYAAACGcpEgAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAALK5JREFUeJzt3XlcE9f6P/BPQBIUSFgDyCaLV0FRW7SaulFBUNFqxbVWUSkqArfqrVZal2p7L9b21q2urUXb6vWKW9W6FDesGi2iKKJS9KJYMaBQwqIEgfP7w1/m65CgBBEYfN6vV16aM2fmnCczPDmcnAwixhgDIYQQQTJq7A4QQgipO0rihBAiYJTECSFEwCiJE0KIgFESJ4QQAaMkTgghAkZJnBBCBIySOCGECBglcUIIEbBmn8RFIhGio6MbuxuvDH9/f3Ts2LFR2vX392/wdknDmThxItq0adPY3XiuTZs2QSQS4fz58w3SnmCT+M2bNzF16lR4eHjA1NQUUqkUPXv2xIoVK/Do0aPG7t4Ly8nJwaefforU1NQGa/Pq1av49NNPcevWrQZrkxChWrNmDTZt2tTY3UCLxu5AXfzyyy8YOXIkJBIJJkyYgI4dO6K8vBynTp3C7NmzkZ6ejg0bNjR2N19ITk4OFi1ahDZt2qBLly4N0ubVq1exaNEi+Pv7C2LE87Rff/21sbtAXjFr1qyBra0tJk6c2Kj9EFwSz8rKwpgxY+Dm5oZjx47B0dGR2xYVFYUbN27gl19+adA+lZaWwszMrEHbrCsh9dUQYrG4QdsrKyuDWCyGkZFgf5klzYTgrsClS5eipKQEGzdu5CVwLS8vL3zwwQc65Xv27EHHjh0hkUjQoUMHHDp0iLf99u3bmD59Otq1a4eWLVvCxsYGI0eO1Jla0M53JSUlYfr06ZDL5XB2djboGABQWFiImTNnok2bNpBIJHB2dsaECRPw4MEDnDhxAt26dQMATJo0CSKRCCKRiPer27lz5zBgwADIZDK0atUKffv2xenTp3ltfPrppxCJRLh69SreffddWFlZoVevXnpf102bNmHkyJEAgLfeeotr88SJE1ydNWvWoEOHDpBIJGjdujWioqJQWFio93hP+/XXX9GqVSuMHTsWFRUVAIDr169jxIgRsLa2hqmpKbp27Yq9e/fqfa1Pnz6NWbNmwc7ODmZmZnjnnXdw//59Xt3qc+Jt2rThYqj+eDqmu3fvYvLkybC3t+euje+//5537BMnTkAkEmHbtm2YN28enJyc0KpVKxQVFdUY87Zt2+Dn5wcLCwtIpVL4+vpixYoVvDqFhYWYMWMGXFxcIJFI4OXlhS+++AJVVVU69SZOnAiZTAZLS0uEhYUhNTVV55qo6XMBfXPJVVVVWL58OTp06ABTU1PY29tj6tSp+Ouvv3j12rRpg8GDB+PUqVN44403YGpqCg8PD/zwww867TzrmtbSaDRYuHAhvLy8IJFI4OLigjlz5kCj0dT4Wj7Ly4jj8uXL6Nu3L1q2bAlnZ2d8/vnniI+Ph0gk4n6W27Rpg/T0dCQlJXHXVfXXXqPRPPe6PX/+PIKDg2Fra4uWLVvC3d0dkydPNug1ENxIfN++ffDw8MCbb75Z631OnTqFXbt2Yfr06bCwsMDKlSsRGhqK7Oxs2NjYAACSk5Nx5swZjBkzBs7Ozrh16xbWrl0Lf39/XL16Fa1ateIdc/r06bCzs8OCBQtQWlpq0DFKSkrQu3dvXLt2DZMnT8brr7+OBw8eYO/evfjzzz/h7e2NxYsXY8GCBZgyZQp69+4NAFzMx44dw8CBA+Hn54eFCxfCyMgI8fHx6NevH3777Te88cYbvL6OHDkSbdu2xb/+9S/UdOfhPn364O9//ztWrlyJjz/+GN7e3gDA/fvpp59i0aJFCAwMRGRkJDIyMrB27VokJyfj9OnTMDEx0Xvc/fv3Y8SIERg9ejS+//57GBsbIz09HT179oSTkxPmzp0LMzMzbN++HcOGDcPOnTvxzjvv8I4RExMDKysrLFy4ELdu3cLy5csRHR2N//73vzWe8+XLl6OkpIRXtmzZMqSmpnLnPDc3Fz169OA+/Lazs8PBgwcRHh6OoqIizJgxg7f/Z599BrFYjA8//BAajabG0X9iYiLGjh2LgIAAfPHFFwCAa9eu4fTp09wA4+HDh+jbty/u3r2LqVOnwtXVFWfOnEFsbCzu3buH5cuXAwAYYxg6dChOnTqFadOmwdvbG7t370ZYWFiNsdfG1KlTsWnTJkyaNAl///vfkZWVhW+++QYXL17UOZ83btzAiBEjEB4ejrCwMHz//feYOHEi/Pz80KFDBwDPv6ZtbW1RVVWFt99+G6dOncKUKVPg7e2NtLQ0LFu2DH/88Qf27NnT6HHcvXuXG8TExsbCzMwM3333HSQSCa/d5cuXIyYmBubm5vjkk08AAPb29rw6z7tu8/LyEBQUBDs7O8ydOxeWlpa4desWdu3aZdiLwARErVYzAGzo0KG13gcAE4vF7MaNG1zZpUuXGAC2atUqruzhw4c6+yqVSgaA/fDDD1xZfHw8A8B69erFKioqePVre4wFCxYwAGzXrl069auqqhhjjCUnJzMALD4+Xmd727ZtWXBwMFdX27a7uzvr378/V7Zw4UIGgI0dO1anHX0SEhIYAHb8+HFeeV5eHhOLxSwoKIhVVlZy5d988w0DwL7//nuurG/fvqxDhw6MMcZ27tzJTExMWEREBG+/gIAA5uvry8rKynhxvfnmm6xt27Zcmfa1DgwM5MU6c+ZMZmxszAoLC3nt9u3bt8bYtm/fzgCwxYsXc2Xh4eHM0dGRPXjwgFd3zJgxTCaTcefz+PHjDADz8PDQe46r++CDD5hUKtW5Pp722WefMTMzM/bHH3/wyufOncuMjY1ZdnY2Y4yxPXv2MABs6dKlXJ2KigrWu3dvneujptcgLCyMubm5cc9/++03BoBt2bKFV+/QoUM65W5ubgwAO3nyJFeWl5fHJBIJ+8c//sGV1eaa/vHHH5mRkRH77bffeNvXrVvHALDTp0/r7NvQccTExDCRSMQuXrzIleXn5zNra2sGgGVlZXHlHTp00Pt61/a63b17NwPAkpOTnxn38whqOkX766uFhYVB+wUGBsLT05N73qlTJ0ilUvzvf//jylq2bMn9//Hjx8jPz4eXlxcsLS1x4cIFnWNGRETA2NiYV1bbY+zcuROdO3fWGXECT5ZEPktqaioyMzPx7rvvIj8/Hw8ePMCDBw9QWlqKgIAAnDx5UufX8WnTpj3zmM9z5MgRlJeXY8aMGbw54IiICEilUr2fQfznP//B6NGjMXXqVKxfv57br6CgAMeOHcOoUaNQXFzM9T8/Px/BwcHIzMzE3bt3eceaMmUK73Xp3bs3Kisrcfv27Vr1/+rVq5g8eTKGDh2KefPmAXgywt25cyeGDBkCxhjXjwcPHiA4OBhqtVrnvIeFhfHOcU0sLS1RWlqKxMTEGuskJCSgd+/esLKy4rUdGBiIyspKnDx5EgBw4MABtGjRApGRkdy+xsbGiImJqVXsNbUtk8nQv39/Xtt+fn4wNzfH8ePHefV9fHy43wYBwM7ODu3ateP9/NTmmk5ISIC3tzfat2/Pa7dfv34AoNNuY8Rx6NAhKBQK3mICa2trjBs3zqC+Ac+/bi0tLQE8+W318ePHBh9fS1DTKVKpFABQXFxs0H6urq46ZVZWVrx5s0ePHiEuLg7x8fG4e/cub9pBrVbr7O/u7q5TVttj3Lx5E6GhoQbFoJWZmQkAz/x1Wq1Ww8rK6pl9NYT2omvXrh2vXCwWw8PDQyeZZmVl4b333sPIkSOxatUq3rYbN26AMYb58+dj/vz5etvLy8uDk5MT97z6+dPGVn3eU5+ioiIMHz4cTk5O+OGHH7gfqvv376OwsBAbNmyocSVTXl4e73ltX8fp06dj+/btGDhwIJycnBAUFIRRo0ZhwIABXJ3MzExcvnwZdnZ2z2z79u3bcHR0hLm5OW979XNhiMzMTKjVasjl8me2rVWbn5/aXNOZmZm4du3ac2OurZcRx+3bt6FQKHTqeXl5GdQ3fe1Vv2779u2L0NBQLFq0CMuWLYO/vz+GDRuGd999V2f65lkEl8Rbt26NK1euGLRf9RGz1tNJNiYmBvHx8ZgxYwYUCgVkMhlEIhHGjBmjM7IFoHdEZugx6kJ7nC+//LLGpYfVf+BrM3qsT46OjnB0dMSBAwdw/vx5dO3aldum7f+HH36I4OBgvftX/4GpzfmrycSJE5GTk4Pff/+dGwQ83Y/33nuvxjfETp068Z7X9nWUy+VITU3F4cOHcfDgQRw8eBDx8fGYMGECNm/ezLXfv39/zJkzR+8x/va3v9WqraeJRCK9r0llZSXveVVVFeRyObZs2aL3ONWT7Iu8/tXb9fX1xddff613u4uLi8HHa4w4aut57YlEIuzYsQNnz57Fvn37cPjwYUyePBn//ve/cfbsWZ2f45oIKokDwODBg7FhwwYolUq975h1tWPHDoSFheHf//43V1ZWVlar1ReGHsPT0/O5b0Q1Tatop4WkUikCAwNr3bfaqKlNNzc3AEBGRgY8PDy48vLycmRlZen0w9TUFPv370e/fv0wYMAAJCUlcR8cafc3MTGp9/5Xt2TJEuzZswe7du1C+/btedvs7OxgYWGBysrKl9IPsViMIUOGYMiQIaiqqsL06dOxfv16zJ8/H15eXvD09ERJSclz23Zzc8PRo0dRUlLC+6HOyMjQqWtlZcWbGtCq/puSp6cnjhw5gp49e9bbG3xtrmlPT09cunQJAQEBz502rG2b9R2Hm5sbbty4oVOur6w+YgCAHj16oEePHvjnP/+JrVu3Yty4cdi2bRvef//9Wu0vqDlxAJgzZw7MzMzw/vvvIzc3V2f7zZs3dZZy1YaxsbHOO/KqVat0RjH1cYzQ0FBcunQJu3fv1jmGdn/tWu7qbwB+fn7w9PTEV199pbP6AoDOEiZD1NRmYGAgxGIxVq5cyYtv48aNUKvVCAkJ0TmWTCbD4cOHIZfL0b9/f9y8eRPAk1Gqv78/1q9fj3v37tVr/5925MgRzJs3D5988gmGDRums93Y2BihoaHYuXOn3uTzIv3Iz8/nPTcyMuJG9dqldKNGjYJSqcThw4d19i8sLOSWYg4aNAgVFRVYu3Ytt72yslJnmgp4ktSuX7/O6/ulS5d0lp6OGjUKlZWV+Oyzz3SOUVFRYdDARas21/SoUaNw9+5dfPvttzp1Hj16xK3yqq2XEUdwcDCUSiXvm9IFBQV6R/tmZmZ1akPrr7/+0skX2t+uDVlyKbiRuKenJ7Zu3YrRo0fD29ub943NM2fOICEhoU7foBo8eDB+/PFHyGQy+Pj4QKlU4siRI9xytPo8xuzZs7Fjxw6MHDkSkydPhp+fHwoKCrB3716sW7cOnTt3hqenJywtLbFu3TpYWFjAzMwM3bt3h7u7O7777jsMHDgQHTp0wKRJk+Dk5IS7d+/i+PHjkEql2Ldvn8HxA08uIGNjY3zxxRdQq9WQSCTo168f5HI5YmNjsWjRIgwYMABvv/02MjIysGbNGnTr1g3vvfee3uPZ2toiMTERvXr1QmBgIE6dOgUnJyesXr0avXr1gq+vLyIiIuDh4YHc3FwolUr8+eefuHTpUp36/7SxY8fCzs4Obdu2xU8//cTb1r9/f9jb22PJkiU4fvw4unfvjoiICPj4+KCgoAAXLlzAkSNHUFBQUKe233//fRQUFKBfv35wdnbG7du3sWrVKnTp0oVbsjl79mzs3bsXgwcP5pa5lZaWIi0tDTt27MCtW7dga2uLIUOGoGfPnpg7dy5u3boFHx8f7Nq1S+/nNJMnT8bXX3+N4OBghIeHIy8vD+vWrUOHDh14a9r79u2LqVOnIi4uDqmpqQgKCoKJiQkyMzORkJCAFStWYMSIEQbFXJtrevz48di+fTumTZuG48ePo2fPnqisrMT169exfft2HD58mDf19jwvI445c+bgp59+Qv/+/RETE8MtMXR1dUVBQQFv9O3n54e1a9fi888/h5eXF+RyOfchbW1s3rwZa9aswTvvvANPT08UFxfj22+/hVQqxaBBg2rf6Rda29KI/vjjDxYREcHatGnDxGIxs7CwYD179mSrVq3iLV0DwKKionT2d3NzY2FhYdzzv/76i02aNInZ2toyc3NzFhwczK5fv65TT7t8SN+yoNoeg7Eny5aio6OZk5MTE4vFzNnZmYWFhfGWu/3888/Mx8eHtWjRQmc52cWLF9nw4cOZjY0Nk0gkzM3NjY0aNYodPXqUq6NdYnj//v1av67ffvst8/DwYMbGxjrLDb/55hvWvn17ZmJiwuzt7VlkZCT766+/ePs/vcRQ68aNG8zR0ZF5e3tzfbl58yabMGECc3BwYCYmJszJyYkNHjyY7dixg9uvptdau+Tv6b5VX14HoMbH0/vl5uayqKgo5uLiwkxMTJiDgwMLCAhgGzZs0GkvISGhVq/hjh07WFBQEJPL5UwsFjNXV1c2depUdu/ePV694uJiFhsby7y8vJhYLGa2trbszTffZF999RUrLy/n6uXn57Px48czqVTKZDIZGz9+PLt48aLeJag//fQT8/DwYGKxmHXp0oUdPnxYZ2me1oYNG5ifnx9r2bIls7CwYL6+vmzOnDksJyeHq+Pm5sZCQkJ09tW3nLE213R5eTn74osvWIcOHZhEImFWVlbMz8+PLVq0iKnV6me+rg0Vx8WLF1nv3r2ZRCJhzs7OLC4ujq1cuZIBYCqViqunUqlYSEgIs7CwYAC449T2ur1w4QIbO3Ysc3V1ZRKJhMnlcjZ48GB2/vz5Z74O1YkYe0mz+oSQl+bWrVtwd3dHfHx8o9+741UwY8YMrF+/HiUlJTV+YNlYBDcnTgghL1P1u6Dm5+fjxx9/RK9evZpcAgcEOCdOCCEvk0KhgL+/P7y9vZGbm4uNGzeiqKioxu81NDZK4oQQ8pRBgwZhx44d2LBhA0QiEV5//XVs3LgRffr0aeyu6UVz4oQQImA0J04IIQJGSZwQQgRMkHPiVVVVyMnJgYWFRb199ZUQQhoTYwzFxcVo3bq1QX8xSpBJPCcnx+Cb5RBCiBDcuXOH+2thtSHIJK69n/idO3d4d6YjhBChKioqgouLi8F/L0GQSVw7hSKVSimJE0KaFUOniOmDTUIIETBK4oQQImCUxAkhRMAoiRNCiIBREieEEAET5OoUQhpSm7m/6C2/tUT3z9IR0tBoJE4IIQJGSZwQQgSMkjghhAgYJXFCCBEwSuKEECJglMQJIUTAKIkTQoiA0TpxQv6/mtaDE9KU0UicEEIEjJI4IYQI2Asl8SVLlkAkEmHGjBlcWVlZGaKiomBjYwNzc3OEhoYiNzeXt192djZCQkLQqlUryOVyzJ49GxUVFS/SFUIIeSXVOYknJydj/fr16NSpE6985syZ2LdvHxISEpCUlIScnBwMHz6c215ZWYmQkBCUl5fjzJkz2Lx5MzZt2oQFCxbUPQpCCHlF1SmJl5SUYNy4cfj2229hZWXFlavVamzcuBFff/01+vXrBz8/P8THx+PMmTM4e/YsAODXX3/F1atX8dNPP6FLly4YOHAgPvvsM6xevRrl5eX1ExUhhLwi6pTEo6KiEBISgsDAQF55SkoKHj9+zCtv3749XF1doVQqAQBKpRK+vr6wt7fn6gQHB6OoqAjp6el629NoNCgqKuI9CCGE1GGJ4bZt23DhwgUkJyfrbFOpVBCLxbC0tOSV29vbQ6VScXWeTuDa7dpt+sTFxWHRokWGdpUQQpo9g0bid+7cwQcffIAtW7bA1NT0ZfVJR2xsLNRqNfe4c+dOg7VNCCFNmUFJPCUlBXl5eXj99dfRokULtGjRAklJSVi5ciVatGgBe3t7lJeXo7CwkLdfbm4uHBwcAAAODg46q1W0z7V1qpNIJJBKpbwHIYQQA5N4QEAA0tLSkJqayj26du2KcePGcf83MTHB0aNHuX0yMjKQnZ0NhUIBAFAoFEhLS0NeXh5XJzExEVKpFD4+PvUUFiGEvBoMmhO3sLBAx44deWVmZmawsbHhysPDwzFr1ixYW1tDKpUiJiYGCoUCPXr0AAAEBQXBx8cH48ePx9KlS6FSqTBv3jxERUVBIpHUU1iEPEF/Wo00d/V+75Rly5bByMgIoaGh0Gg0CA4Oxpo1a7jtxsbG2L9/PyIjI6FQKGBmZoawsDAsXry4vrtCCCHN3gsn8RMnTvCem5qaYvXq1Vi9enWN+7i5ueHAgQMv2jQhhLzy6N4phBAiYHQrWtJsNOVbyRoyN0/z+MQQNBInhBABoyROCCECRtMphNSjpjylQ5onSuJEcChREvJ/KIkTUkf0ZkKaAkripEnQlxBf5moMSsCkuaAPNgkhRMAoiRNCiIBREieEEAGjJE4IIQJGH2ySJos+fCTk+WgkTgghAkZJnBBCBIySOCGECBjNiRMiEHSLWqIPjcQJIUTAaCROSCOiFTjkRdFInBBCBIxG4oQ0QzR//uqgkTghhAiYQUl87dq16NSpE6RSKaRSKRQKBQ4ePMhtLysrQ1RUFGxsbGBubo7Q0FDk5ubyjpGdnY2QkBC0atUKcrkcs2fPRkVFRf1EQwghrxiDkrizszOWLFmClJQUnD9/Hv369cPQoUORnp4OAJg5cyb27duHhIQEJCUlIScnB8OHD+f2r6ysREhICMrLy3HmzBls3rwZmzZtwoIFC+o3KkIIeUWIGGPsRQ5gbW2NL7/8EiNGjICdnR22bt2KESNGAACuX78Ob29vKJVK9OjRAwcPHsTgwYORk5MDe3t7AMC6devw0Ucf4f79+xCLxbVqs6ioCDKZDGq1GlKp9EW6T5oIWqVRd/rmuWlOXHjqmtfq/MFmZWUlEhISUFpaCoVCgZSUFDx+/BiBgYFcnfbt28PV1ZVL4kqlEr6+vlwCB4Dg4GBERkYiPT0dr732mt62NBoNNBoN97yoqKiu3SaNjJI1IfXL4CSelpYGhUKBsrIymJubY/fu3fDx8UFqairEYjEsLS159e3t7aFSqQAAKpWKl8C127XbahIXF4dFixYZ2lVCXgn0xvhqMziJt2vXDqmpqVCr1dixYwfCwsKQlJT0MvrGiY2NxaxZs7jnRUVFcHFxealtkhdDiYWQhmFwEheLxfDy8gIA+Pn5ITk5GStWrMDo0aNRXl6OwsJC3mg8NzcXDg4OAAAHBwf8/vvvvONpV69o6+gjkUggkUgM7SohhDR7L7xOvKqqChqNBn5+fjAxMcHRo0e5bRkZGcjOzoZCoQAAKBQKpKWlIS8vj6uTmJgIqVQKHx+fF+0KIYS8cgwaicfGxmLgwIFwdXVFcXExtm7dihMnTuDw4cOQyWQIDw/HrFmzYG1tDalUipiYGCgUCvTo0QMAEBQUBB8fH4wfPx5Lly6FSqXCvHnzEBUVRSNtQgipA4OSeF5eHiZMmIB79+5BJpOhU6dOOHz4MPr37w8AWLZsGYyMjBAaGgqNRoPg4GCsWbOG29/Y2Bj79+9HZGQkFAoFzMzMEBYWhsWLF9dvVIQQ8op44XXijYHWiTd99MFm00TrxJuuBl8nTogWJWxCGg/dAIsQQgSMkjghhAgYTacQ8grRN/VF8+TCRiNxQggRMBqJE/KKozseChuNxAkhRMAoiRNCiIBREieEEAGjJE4IIQJGSZwQQgSMVqeQWqOv1xPS9NBInBBCBIxG4kQHjbgJQOvHhYKSOCHEIPTV/aaFplMIIUTAKIkTQoiAURInhBABoyROCCECRkmcEEIEjJI4IYQImEFJPC4uDt26dYOFhQXkcjmGDRuGjIwMXp2ysjJERUXBxsYG5ubmCA0NRW5uLq9OdnY2QkJC0KpVK8jlcsyePRsVFRUvHg0hhLxiDEriSUlJiIqKwtmzZ5GYmIjHjx8jKCgIpaWlXJ2ZM2di3759SEhIQFJSEnJycjB8+HBue2VlJUJCQlBeXo4zZ85g8+bN2LRpExYsWFB/URFCyCtCxBhjdd35/v37kMvlSEpKQp8+faBWq2FnZ4etW7dixIgRAIDr16/D29sbSqUSPXr0wMGDBzF48GDk5OTA3t4eALBu3Tp89NFHuH//PsRi8XPbLSoqgkwmg1qthlQqrWv3SQ3oG5vEUPRlnxdX17z2Qt/YVKvVAABra2sAQEpKCh4/fozAwECuTvv27eHq6solcaVSCV9fXy6BA0BwcDAiIyORnp6O11577UW6RAxECZvUB/qKfuOpcxKvqqrCjBkz0LNnT3Ts2BEAoFKpIBaLYWlpyatrb28PlUrF1Xk6gWu3a7fpo9FooNFouOdFRUV17TYhhDQrdV6dEhUVhStXrmDbtm312R+94uLiIJPJuIeLi8tLb5MQQoSgTkk8Ojoa+/fvx/Hjx+Hs7MyVOzg4oLy8HIWFhbz6ubm5cHBw4OpUX62ifa6tU11sbCzUajX3uHPnTl26TQghzY5BSZwxhujoaOzevRvHjh2Du7s7b7ufnx9MTExw9OhRriwjIwPZ2dlQKBQAAIVCgbS0NOTl5XF1EhMTIZVK4ePjo7ddiUQCqVTKexBCCDFwTjwqKgpbt27Fzz//DAsLC24OWyaToWXLlpDJZAgPD8esWbNgbW0NqVSKmJgYKBQK9OjRAwAQFBQEHx8fjB8/HkuXLoVKpcK8efMQFRUFiURS/xESQkgzZlASX7t2LQDA39+fVx4fH4+JEycCAJYtWwYjIyOEhoZCo9EgODgYa9as4eoaGxtj//79iIyMhEKhgJmZGcLCwrB48eIXi4QQQl5BL7ROvLHQOvH6Q0sMyctESwxrr655je6dQgghAkZJnBBCBIySOCGECBglcUIIETBK4oQQImCUxAkhRMAoiRNCiIBREieEEAGjJE4IIQJGSZwQQgTshf6yDyGE1IW+2z3QV/TrhpI4IeSloXvzvHyUxJshGuUQ8uqgOXFCCBEwSuKEECJglMQJIUTAaE78FUEfMBHSPNFInBBCBIySOCGECBhNpwgYTZGQ5qSm65mWxz4bjcQJIUTAKIkTQoiAGZzET548iSFDhqB169YQiUTYs2cPbztjDAsWLICjoyNatmyJwMBAZGZm8uoUFBRg3LhxkEqlsLS0RHh4OEpKSl4oEEIIeRUZnMRLS0vRuXNnrF69Wu/2pUuXYuXKlVi3bh3OnTsHMzMzBAcHo6ysjKszbtw4pKenIzExEfv378fJkycxZcqUukdBCCGvKIM/2Bw4cCAGDhyodxtjDMuXL8e8efMwdOhQAMAPP/wAe3t77NmzB2PGjMG1a9dw6NAhJCcno2vXrgCAVatWYdCgQfjqq6/QunXrFwiHEEJeLfU6J56VlQWVSoXAwECuTCaToXv37lAqlQAApVIJS0tLLoEDQGBgIIyMjHDu3Ln67A4hhDR79brEUKVSAQDs7e155fb29tw2lUoFuVzO70SLFrC2tubqVKfRaKDRaLjnRUVF9dltQggRLEGsTomLi4NMJuMeLi4ujd0lQghpEuo1iTs4OAAAcnNzeeW5ubncNgcHB+Tl5fG2V1RUoKCggKtTXWxsLNRqNfe4c+dOfXabEEIEq16nU9zd3eHg4ICjR4+iS5cuAJ5MfZw7dw6RkZEAAIVCgcLCQqSkpMDPzw8AcOzYMVRVVaF79+56jyuRSCCRSOqzq4QQgaBvcj6bwUm8pKQEN27c4J5nZWUhNTUV1tbWcHV1xYwZM/D555+jbdu2cHd3x/z589G6dWsMGzYMAODt7Y0BAwYgIiIC69atw+PHjxEdHY0xY8bQypQa0NfrCSE1MTiJnz9/Hm+99Rb3fNasWQCAsLAwbNq0CXPmzEFpaSmmTJmCwsJC9OrVC4cOHYKpqSm3z5YtWxAdHY2AgAAYGRkhNDQUK1eurIdwCCHk1SJijLHG7oShioqKIJPJoFarIZVKG7s7Lx2NxAnR1dymU+qa1wSxOoUQQoh+lMQJIUTAKIkTQoiAURInhBABo7/sQwgRJH0f+De3Dztrg5J4E0MrUQghhqDpFEIIETBK4oQQImA0ndJIaNqEEFIfKIkTQpqNV/FmWTSdQgghAkZJnBBCBIySOCGECBglcUIIETBK4oQQImC0OuUlo6WEhJCXiUbihBAiYDQSJ4Q0e835ZlmUxOsRTZ0QIhzN5YtBNJ1CCCECRkmcEEIEjKZT6oCmTQhpvoQ2zdJoI/HVq1ejTZs2MDU1Rffu3fH77783VlcIIUSwGiWJ//e//8WsWbOwcOFCXLhwAZ07d0ZwcDDy8vIaozuEECJYIsYYa+hGu3fvjm7duuGbb74BAFRVVcHFxQUxMTGYO3fuc/cvKiqCTCaDWq2GVCp9af2kaRNCyLPU5xRLXfNag8+Jl5eXIyUlBbGxsVyZkZERAgMDoVQq9e6j0Wig0Wi452q1GsCToF+mKs3Dl3p8Qoiw1WcO0h7L0HF1gyfxBw8eoLKyEvb29rxye3t7XL9+Xe8+cXFxWLRokU65i4vLS+kjIYTUhmx5/R+zuLgYMpms1vUFsTolNjYWs2bN4p5XVVWhoKAANjY2EIlEtT5OUVERXFxccOfOnZc6DdNYmnN8zTk2oHnH15xjA+ovPsYYiouL0bp1a4P2a/AkbmtrC2NjY+Tm5vLKc3Nz4eDgoHcfiUQCiUTCK7O0tKxzH6RSabO8mLSac3zNOTagecfXnGMD6ic+Q0bgWg2+OkUsFsPPzw9Hjx7lyqqqqnD06FEoFIqG7g4hhAhao0ynzJo1C2FhYejatSveeOMNLF++HKWlpZg0aVJjdIcQQgSrUZL46NGjcf/+fSxYsAAqlQpdunTBoUOHdD7srG8SiQQLFy7UmZppLppzfM05NqB5x9ecYwMaP75GWSdOCCGkftANsAghRMAoiRNCiIBREieEEAGjJE4IIQLWLJL4yZMnMWTIELRu3RoikQh79uzhbWeMYcGCBXB0dETLli0RGBiIzMxMXp2CggKMGzcOUqkUlpaWCA8PR0lJSQNGod/zYps4cSJEIhHvMWDAAF6dphpbXFwcunXrBgsLC8jlcgwbNgwZGRm8OmVlZYiKioKNjQ3Mzc0RGhqq80Wx7OxshISEoFWrVpDL5Zg9ezYqKioaMhQdtYnN399f59xNmzaNV6cpxgYAa9euRadOnbgvuCgUChw8eJDbLtTzpvW8+JrUuWPNwIEDB9gnn3zCdu3axQCw3bt387YvWbKEyWQytmfPHnbp0iX29ttvM3d3d/bo0SOuzoABA1jnzp3Z2bNn2W+//ca8vLzY2LFjGzgSXc+LLSwsjA0YMIDdu3ePexQUFPDqNNXYgoODWXx8PLty5QpLTU1lgwYNYq6urqykpISrM23aNObi4sKOHj3Kzp8/z3r06MHefPNNbntFRQXr2LEjCwwMZBcvXmQHDhxgtra2LDY2tjFC4tQmtr59+7KIiAjeuVOr1dz2phobY4zt3buX/fLLL+yPP/5gGRkZ7OOPP2YmJibsypUrjDHhnjet58XXlM5ds0jiT6ue6KqqqpiDgwP78ssvubLCwkImkUjYf/7zH8YYY1evXmUAWHJyMlfn4MGDTCQSsbt37zZY35+npiQ+dOjQGvcRSmyMMZaXl8cAsKSkJMbYk/NkYmLCEhISuDrXrl1jAJhSqWSMPXmTMzIyYiqViquzdu1aJpVKmUajadgAnqF6bIw9SQQffPBBjfsIJTYtKysr9t133zWr8/Y0bXyMNa1z1yymU54lKysLKpUKgYGBXJlMJkP37t25W98qlUpYWlqia9euXJ3AwEAYGRnh3LlzDd5nQ504cQJyuRzt2rVDZGQk8vPzuW1Cik17i2Fra2sAQEpKCh4/fsw7d+3bt4erqyvv3Pn6+vK+KBYcHIyioiKkp6c3YO+frXpsWlu2bIGtrS06duyI2NhYPHz4f7c/FkpslZWV2LZtG0pLS6FQKJrVeQN049NqKudOEHcxfBEqlQoA9N76VrtNpVJBLpfztrdo0QLW1tZcnaZqwIABGD58ONzd3XHz5k18/PHHGDhwIJRKJYyNjQUTW1VVFWbMmIGePXuiY8eOAJ6cF7FYrHOzs+rnTt+51W5rCvTFBgDvvvsu3Nzc0Lp1a1y+fBkfffQRMjIysGvXLgBNP7a0tDQoFAqUlZXB3Nwcu3fvho+PD1JTU5vFeaspPqBpnbtmn8SbuzFjxnD/9/X1RadOneDp6YkTJ04gICCgEXtmmKioKFy5cgWnTp1q7K7Uu5pimzJlCvd/X19fODo6IiAgADdv3oSnp2dDd9Ng7dq1Q2pqKtRqNXbs2IGwsDAkJSU1drfqTU3x+fj4NKlz1+ynU7S3t33WrW8dHBx0/r5nRUUFCgoKarw9blPl4eEBW1tb3LhxA4AwYouOjsb+/ftx/PhxODs7c+UODg4oLy9HYWEhr371c6fv3Gq3NbaaYtOne/fuAMA7d005NrFYDC8vL/j5+SEuLg6dO3fGihUrmsV5A2qOT5/GPHfNPom7u7vDwcGBd+vboqIinDt3jpvfUigUKCwsREpKClfn2LFjqKqq4k6OUPz555/Iz8+Ho6MjgKYdG2MM0dHR2L17N44dOwZ3d3fedj8/P5iYmPDOXUZGBrKzs3nnLi0tjfdGlZiYCKlUyv3q2xieF5s+qampAMA7d00xtppUVVVBo9EI+rw9izY+fRr13NXrx6SNpLi4mF28eJFdvHiRAWBff/01u3jxIrt9+zZj7MkSQ0tLS/bzzz+zy5cvs6FDh+pdYvjaa6+xc+fOsVOnTrG2bds2iWV4z4qtuLiYffjhh0ypVLKsrCx25MgR9vrrr7O2bduysrIy7hhNNbbIyEgmk8nYiRMneEu1Hj58yNWZNm0ac3V1ZceOHWPnz59nCoWCKRQKbrt2KVdQUBBLTU1lhw4dYnZ2do2+VO15sd24cYMtXryYnT9/nmVlZbGff/6ZeXh4sD59+nDHaKqxMcbY3LlzWVJSEsvKymKXL19mc+fOZSKRiP3666+MMeGeN61nxdfUzl2zSOLHjx9nAHQeYWFhjLEnywznz5/P7O3tmUQiYQEBASwjI4N3jPz8fDZ27Fhmbm7OpFIpmzRpEisuLm6EaPieFdvDhw9ZUFAQs7OzYyYmJszNzY1FRETwljUx1nRj0xcXABYfH8/VefToEZs+fTqzsrJirVq1Yu+88w67d+8e7zi3bt1iAwcOZC1btmS2trbsH//4B3v8+HEDR8P3vNiys7NZnz59mLW1NZNIJMzLy4vNnj2bt9aYsaYZG2OMTZ48mbm5uTGxWMzs7OxYQEAAl8AZE+5503pWfE3t3NGtaAkhRMCa/Zw4IYQ0Z5TECSFEwCiJE0KIgFESJ4QQAaMkTgghAkZJnBBCBIySOCGECBglcUIIETBK4oQQImCUxAkhRMAoiRNCiIBREieEEAH7f1NELUi/qMBYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_lengths = [len(t) for t in tok.encode(test_texts)['tokens']]\n",
    "plt.figure(figsize=(4, 2))\n",
    "plt.hist(tokenized_lengths, bins=50)\n",
    "plt.title('Character tokenizer sequence lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized\n",
      "['[BOS]', 'kelly', 'was', 'at', 'home', ',', 'trying', 'to', 'sleep', '.', 'suddenly', ',', 'she', 'heard', 'footsteps', 'in', 'her', 'kitchen', '.', 'she', 'grabbed', 'a', 'gun', 'and', 'stood', 'at', 'the', 'top', 'of', 'the', 'stairs', '.', 'she', 'warned', 'whoever', 'it', 'was', 'that', 'she', 'was', 'armed', '.', 'she', 'heard', 'them', 'run', 'out', 'of', 'the', 'house', 'and', 'then', 'called', 'police', '.', '[EOS]']\n",
      "\n",
      "['[BOS]', 'i', 'bought', 'a', '1969', 'mercury', 'montego', 'with', 'a', 'loose', 'front', 'seat', '.', 'the', 'seat', 'was', 'loose', 'because', 'the', 'car', \"'\", 's', 'floor', 'had', 'rusted', 'through', '.', 'i', 'removed', 'the', 'seat', 'and', 'repaired', 'the', 'floor', 'with', 'pieces', 'of', 'sheet', 'metal', '.', 'my', 'repair', 'held', 'the', 'seat', 'firmly', 'in', 'place', 'after', 'i', 'reinstalled', 'it', '.', 'the', 'car', 'then', 'successfully', 'passed', 'the', 'safety', 'inspection', '.', '[EOS]']\n",
      "\n",
      "Detokenized\n",
      "kelly was at home , trying to sleep . suddenly , she heard footsteps in her kitchen . she grabbed a gun and stood at the top of the stairs . she warned whoever it was that she was armed . she heard them run out of the house and then called police .\n",
      "\n",
      "i bought a 1969 mercury montego with a loose front seat . the seat was loose because the car ' s floor had rusted through . i removed the seat and repaired the floor with pieces of sheet metal . my repair held the seat firmly in place after i reinstalled it . the car then successfully passed the safety inspection .\n",
      "\n",
      "Vocab size: 11141\n"
     ]
    }
   ],
   "source": [
    "tok = WordTokenizer(train_texts)\n",
    "\n",
    "tokenized = tok.encode(train_texts[idxs])\n",
    "print('Tokenized')\n",
    "print_texts(tokenized['tokens'])\n",
    "print('Detokenized')\n",
    "print_texts(tok.decode(tokenized['input_ids']))\n",
    "\n",
    "print(f'Vocab size: {len(tok.token2id)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_lengths = [len(t) for t in tok.encode(test_texts)['tokens']]\n",
    "plt.figure(figsize=(4, 2))\n",
    "plt.hist(tokenized_lengths, bins=50)\n",
    "plt.title('Word tokenizer sequence lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokenized\n",
      "['[BOS]', 'kelly', 'was', 'at', 'home', ',', 'trying', 'to', 'sleep', '.', 'suddenly', ',', 'she', 'heard', 'foot', '##st', '##ep', '##s', 'in', 'her', 'kitchen', '.', 'she', 'grabbed', 'a', 'gun', 'and', 'stood', 'at', 'the', 'top', 'of', 'the', 'stairs', '.', 'she', 'warned', 'who', '##ever', 'it', 'was', 'that', 'she', 'was', 'ar', '##med', '.', 'she', 'heard', 'them', 'run', 'out', 'of', 'the', 'house', 'and', 'then', 'called', 'police', '.', '[EOS]']\n",
      "\n",
      "['[BOS]', 'i', 'bought', 'a', '19', '##6', '##9', 'm', '##erc', '##ury', 'mo', '##nt', '##e', '##g', '##o', 'with', 'a', 'loose', 'front', 'seat', '.', 'the', 'seat', 'was', 'loose', 'because', 'the', 'car', \"'\", 's', 'floor', 'had', 'r', '##usted', 'through', '.', 'i', 'removed', 'the', 'seat', 'and', 'repair', '##ed', 'the', 'floor', 'with', 'pieces', 'of', 'she', '##et', 'metal', '.', 'my', 'repair', 'held', 'the', 'seat', 'fir', '##m', '##ly', 'in', 'place', 'after', 'i', 're', '##in', '##st', '##all', '##ed', 'it', '.', 'the', 'car', 'then', 'successfully', 'passed', 'the', 'sa', '##fet', '##y', 'insp', '##ection', '.', '[EOS]']\n",
      "\n",
      "Detokenized\n",
      "kelly was at home, trying to sleep. suddenly, she heard footsteps in her kitchen. she grabbed a gun and stood at the top of the stairs. she warned whoever it was that she was armed. she heard them run out of the house and then called police.\n",
      "\n",
      "i bought a 1969 mercury montego with a loose front seat. the seat was loose because the car ' s floor had rusted through. i removed the seat and repaired the floor with pieces of sheet metal. my repair held the seat firmly in place after i reinstalled it. the car then successfully passed the safety inspection.\n",
      "\n",
      "Vocab size: 4096\n"
     ]
    }
   ],
   "source": [
    "tok = BPETokenizer(train_texts, vocab_size=4096)\n",
    "\n",
    "tokenized = tok.encode(train_texts[idxs])\n",
    "print('Tokenized')\n",
    "print_texts(tokenized['tokens'])\n",
    "\n",
    "print('Detokenized')\n",
    "print_texts(tok.decode(tokenized['input_ids']))\n",
    "\n",
    "print(f'Vocab size: {len(tok.token2id)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_lengths = [len(t) for t in tok.encode(train_texts)['tokens']]\n",
    "plt.figure(figsize=(4, 2))\n",
    "plt.hist(tokenized_lengths, bins=50)\n",
    "plt.title('BPE 1024 tokenizer sequence lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, hidden_size)\n",
    "\n",
    "        self.W = nn.Linear(hidden_size + hidden_size, hidden_size)\n",
    "        self.O = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_ids, h0: Optional[torch.Tensor] = None):\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        x = self.embeddings(input_ids)\n",
    "\n",
    "        if h0 is None:\n",
    "            h_t = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        else:\n",
    "            h_t = h0\n",
    "\n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]\n",
    "\n",
    "            h_t = torch.tanh(\n",
    "                self.W(torch.cat((x_t, h_t), dim=-1))\n",
    "            )\n",
    "\n",
    "            o_t = self.O(h_t)\n",
    "            outputs.append(o_t)\n",
    "\n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "\n",
    "        return outputs, h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "\n",
    "    accuracies = []\n",
    "    for input_ids in dataloader:\n",
    "        input_ids = input_ids.to(device)\n",
    "\n",
    "        logits, _ = model(input_ids)\n",
    "        \n",
    "        shift_ids = input_ids[:, 1:]\n",
    "        shift_logits = logits[:, :-1]\n",
    "        loss = loss_fn(shift_logits.permute(0, 2, 1), shift_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accuracy = (shift_logits.argmax(-1) == shift_ids).float().mean().item()\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    return np.mean(accuracies)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for input_ids in dataloader:\n",
    "        input_ids = input_ids.to(device)\n",
    "\n",
    "        logits, _ = model(input_ids)\n",
    "        \n",
    "        shift_ids = input_ids[:, 1:]\n",
    "        shift_logits = logits[:, :-1]\n",
    "        loss = loss_fn(shift_logits.permute(0, 2, 1), shift_ids)\n",
    "\n",
    "        accuracies.append((shift_logits.argmax(-1) == shift_ids).float().mean().item())\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    loss = np.mean(losses)\n",
    "    accuracy = np.mean(accuracies)\n",
    "\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate(tokenizer, model, batch_size=4, max_length=40):\n",
    "    input_ids = torch.empty(size=(batch_size, 1), device=device).fill_(tokenizer.bos_token_id).int()\n",
    "    h_t = torch.zeros(batch_size, model.hidden_size, device=device)\n",
    "    gen_ids = []\n",
    "    for i in range(max_length):\n",
    "        logits, h_t = model(input_ids, h_t)\n",
    "        input_ids = Categorical(logits=logits).sample()\n",
    "        gen_ids.append(input_ids)\n",
    "    \n",
    "    return torch.cat(gen_ids, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's train models on different tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def train_rnn_model(tokenizer):    \n",
    "    def collate_fn(batch, max_length=None):\n",
    "        tokens = tokenizer.encode(batch, max_length=max_length)['input_ids']\n",
    "        return pad_sequence(tokens, padding_value=tokenizer.pad_token_id, batch_first=True)\n",
    "    max_length = 150\n",
    "    collate = partial(collate_fn, max_length=max_length)\n",
    "    train_loader = DataLoader(train_texts, collate_fn=collate, shuffle=True, batch_size=256)\n",
    "    test_loader = DataLoader(test_texts, collate_fn=collate, shuffle=False, batch_size=256)\n",
    "    model = RNN(vocab_size=len(tokenizer), hidden_size=512).to(device)\n",
    "\n",
    "    print('Number of parameters:', sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=4e-4, weight_decay=1e-3)\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "    \n",
    "    for epoch in tqdm(range(20)):\n",
    "        train_accuracy = train(model, train_loader, optimizer, loss_fn)\n",
    "        test_accuracy, test_loss = evaluate(model, test_loader, loss_fn)\n",
    "        if epoch % 5 == 0:\n",
    "            print(train_accuracy, test_accuracy, test_loss)\n",
    "    \n",
    "    _, test_loss = evaluate(model, test_loader, loss_fn)\n",
    "    \n",
    "    return model, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Number of parameters: 4723200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:04<01:18,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05761686963851389 0.07558483742177487 6.160120987892151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:22<00:51,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11558546870946884 0.11518476940691472 5.2606532096862795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:40<00:33,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1248983919620514 0.12248268499970436 5.065859866142273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:59<00:14,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13106198459863663 0.12670493684709072 4.956925714015961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:13<00:00,  3.70s/it]\n"
     ]
    }
   ],
   "source": [
    "bpe_tokenizer = BPETokenizer(corpus=train_texts, vocab_size=4096)\n",
    "bpe_rnn, bpe_test_loss = train_rnn_model(bpe_tokenizer)\n",
    "torch.save(bpe_rnn.state_dict(), 'checkpoints/bpe_rnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 4723200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:03<01:01,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0742159198365698 0.1041804663836956 5.520843744277954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:19<00:45,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14468048140406609 0.1473691951483488 4.59027373790741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:35<00:28,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15467707738280295 0.15559826269745827 4.412833058834076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:51<00:12,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1624450169503689 0.16117852926254272 4.328227865695953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:04<00:00,  3.22s/it]\n"
     ]
    }
   ],
   "source": [
    "word_tokenizer = WordTokenizer(corpus=train_texts, vocab_size=4096)\n",
    "word_rnn, word_test_loss = train_rnn_model(word_tokenizer)\n",
    "torch.save(bpe_rnn.state_dict(), 'checkpoints/word_rnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 608850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:03<00:57,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27662071837112306 0.32306850627064704 2.3889542520046234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:18<00:42,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4120487689971924 0.4215001069009304 1.9297221899032593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:33<00:27,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4659665122628212 0.468839792907238 1.7640975922346116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:48<00:12,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49858393222093583 0.5012813329696655 1.6595043033361434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:00<00:00,  3.01s/it]\n"
     ]
    }
   ],
   "source": [
    "char_tokenizer = CharacterTokenizer(corpus=train_texts)\n",
    "char_rnn, char_test_loss = train_rnn_model(char_tokenizer)\n",
    "torch.save(bpe_rnn.state_dict(), 'checkpoints/char_rnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_outputs = generate(bpe_tokenizer, bpe_rnn, batch_size=5000)\n",
    "word_outputs = generate(word_tokenizer, word_rnn, batch_size=5000)\n",
    "char_outputs = generate(char_tokenizer, char_rnn, batch_size=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "## Validation perplexity\n",
    "NLL:\n",
    "$$\n",
    "\\text{NLL} = -\\frac{1}{N} \\sum_{i=1}^{N} \\log P(x_i \\mid x_{<i})\n",
    "$$\n",
    "\n",
    "Perplexity:\n",
    "$$\n",
    "\\text{PPL} = \\exp \\left( \\text{NLL} \\right)\n",
    "= \\exp \\left( -\\frac{1}{N} \\sum_{i=1}^{N} \\log P(x_i \\mid x_{<i}) \\right)\n",
    "$$\n",
    "\n",
    "It would seem like the ideal metric for measuring quality. A good model should give high probability to real texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPE model Val. PPL 133.97045401309768\n",
      "WordPiece model Val. PPL 72.32429163280698\n",
      "Character model Val. PPL 4.956432029092183\n"
     ]
    }
   ],
   "source": [
    "print(\"BPE model Val. PPL\", np.exp(bpe_test_loss.item()))\n",
    "print(\"WordPiece model Val. PPL\", np.exp(word_test_loss.item()))\n",
    "print(\"Character model Val. PPL\", np.exp(char_test_loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation perplexity has several drawbacks.\n",
    "1. It doesn't directly measure the quality of generation.\n",
    "2. Models trained on different tokenizers can't be compared by validation perplexity, because it's averaged over length. Therefore, for a tokenizer with a small vocabulary, the perplexity will always be lower, since the loss of an individual token is lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative perplexity\n",
    "\n",
    "Here, the evaluation pipeline is slightly different:\n",
    "The texts are generated using our model, and likelihood is estimated using some large pre-trained model (for example, GPT2, which you'll learn about later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/echimbulatov/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--perplexity/2d13ebb2e7fff46bcdb4f6893c83bc434f97a9ef7b23f0ed3e16892256232326 (last modified on Wed Jul 30 12:26:17 2025) since it couldn't be found locally at evaluate-metric--perplexity, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "perplexity = evaluate.load(\"perplexity\", module_type=\"metric\", model_id=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ppl(predictions):\n",
    "    torch.cuda.empty_cache()\n",
    "    ppl_list = perplexity.compute(\n",
    "        predictions=predictions, \n",
    "        model_id=\"gpt2\", \n",
    "        device=\"cuda\", \n",
    "        add_start_token=True,\n",
    "    )[\"perplexities\"]\n",
    "    ppl = np.mean(ppl_list)\n",
    "    return ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 46.54it/s]\n",
      "100%|██████████| 313/313 [00:06<00:00, 46.78it/s]\n",
      "100%|██████████| 313/313 [00:04<00:00, 70.35it/s]\n"
     ]
    }
   ],
   "source": [
    "bpe_model_ppl = compute_ppl(bpe_tokenizer.decode(bpe_outputs))\n",
    "word_model_ppl = compute_ppl(word_tokenizer.decode(word_outputs))\n",
    "char_model_ppl = compute_ppl(char_tokenizer.decode(char_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPE RNN generative PPL 1378.8216522155763\n",
      "WordPiece RNN generative PPL 784.8809538238526\n",
      "Character RNN generative PPL 3566.7746478271483\n"
     ]
    }
   ],
   "source": [
    "print(\"BPE RNN generative PPL\", bpe_model_ppl)\n",
    "print(\"WordPiece RNN generative PPL\", word_model_ppl)\n",
    "print(\"Character RNN generative PPL\", char_model_ppl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative perplexity is quite good at distinguishing bad texts from good ones. However, ranking high-quality texts is not as clear.\n",
    "\n",
    "Furthermore, since a different pre-trained model is used as the ground truth assessment, it can break down:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.171130180358887"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_ppl([\"#####.....###...                ......          ####..\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diversity\n",
    "\n",
    "Another simple but important metric is diversity. It can be implemented in various ways, but typically it's the ratio of unique n-grams to all n-grams in the corpus. This metric serves more as an indicator of mode collapse—if it's too low, something's wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def compute_diversity(all_texts_list):\n",
    "    ngram_range = [2, 3, 4]\n",
    "\n",
    "    tokenizer = spacy.load(\"en_core_web_sm\").tokenizer\n",
    "    token_list = []\n",
    "    for sentence in all_texts_list:\n",
    "        token_list.append([str(token) for token in tokenizer(sentence)])\n",
    "    ngram_sets = {}\n",
    "    ngram_counts = defaultdict(int)\n",
    "\n",
    "    metrics = {}\n",
    "    for n in ngram_range:\n",
    "        ngram_sets[n] = set()\n",
    "        for tokens in token_list:\n",
    "            ngram_sets[n].update(ngrams(tokens, n))\n",
    "            ngram_counts[n] += len(list(ngrams(tokens, n)))\n",
    "        metrics[f'{n}gram_repitition'] = (1 - len(ngram_sets[n])/ngram_counts[n])\n",
    "    diversity = 1\n",
    "    for val in metrics.values():\n",
    "        diversity *= (1 - val)\n",
    "    metrics['diversity'] = diversity\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_diversity(bpe_tokenizer.decode(bpe_outputs)))\n",
    "print(compute_diversity(char_tokenizer.decode(char_outputs)))\n",
    "print(compute_diversity(word_tokenizer.decode(word_outputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAUVE\n",
    "\n",
    "This is perhaps the most representative metric, and the one we use most frequently in practice. It's calculated rather cleverly: each text in the generated corpus and the reference corpus is passed through a pre-trained encoder (usually the averaged last hidden layer of GPT2). The texts are then clustered using k-means. Within each cluster, a distance is calculated between the generated and reference texts (the original paper used KL divergence). This way, we try to estimate the similarity of the text distributions.\n",
    "\n",
    "In our experience, this is one of the best metrics, which correlates very well with text quality. It's sensitive to length and \"junk\" tokens. The only drawbacks are noise—the batch size needs to be quite large—and the inability to apply to large models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mauve(predictions, references, model_id='gpt2'):\n",
    "    mauve = evaluate.load(\"mauve\")\n",
    "    assert len(predictions) == len(references)\n",
    "\n",
    "    if len(predictions) == 0:\n",
    "        return 0\n",
    "\n",
    "    results = mauve.compute(\n",
    "        predictions=predictions, references=references,\n",
    "        featurize_model_name=model_id, device_id=0, verbose=False\n",
    "    )\n",
    "\n",
    "    return results.mauve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/echimbulatov/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mauve/653f4690bcc6e9e16df42f9f85bd0f1b59cca1ae2864058dceedc595f26f6705 (last modified on Tue Jul 29 18:45:49 2025) since it couldn't be found locally at evaluate-metric--mauve, or remotely on the Hugging Face Hub.\n",
      "Featurizing p: 100%|██████████| 5000/5000 [00:35<00:00, 141.15it/s]\n",
      "Featurizing q: 100%|██████████| 5000/5000 [00:35<00:00, 141.37it/s]\n",
      "WARNING clustering 10000 points to 500 centroids: please provide at least 19500 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004329329138350581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/echimbulatov/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mauve/653f4690bcc6e9e16df42f9f85bd0f1b59cca1ae2864058dceedc595f26f6705 (last modified on Tue Jul 29 18:45:49 2025) since it couldn't be found locally at evaluate-metric--mauve, or remotely on the Hugging Face Hub.\n",
      "Featurizing p: 100%|██████████| 5000/5000 [00:35<00:00, 140.34it/s]\n",
      "Featurizing q: 100%|██████████| 5000/5000 [00:34<00:00, 143.33it/s]\n",
      "WARNING clustering 10000 points to 500 centroids: please provide at least 19500 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004430649611516761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/echimbulatov/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mauve/653f4690bcc6e9e16df42f9f85bd0f1b59cca1ae2864058dceedc595f26f6705 (last modified on Tue Jul 29 18:45:49 2025) since it couldn't be found locally at evaluate-metric--mauve, or remotely on the Hugging Face Hub.\n",
      "Featurizing p: 100%|██████████| 5000/5000 [00:34<00:00, 142.96it/s]\n",
      "Featurizing q: 100%|██████████| 5000/5000 [00:34<00:00, 143.16it/s]\n",
      "WARNING clustering 10000 points to 500 centroids: please provide at least 19500 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004282822136388958\n"
     ]
    }
   ],
   "source": [
    "print(compute_mauve(bpe_tokenizer.decode(bpe_outputs), test_texts[:5000]))\n",
    "print(compute_mauve(char_tokenizer.decode(char_outputs), test_texts[:5000]))\n",
    "print(compute_mauve(word_tokenizer.decode(word_outputs), test_texts[:5000]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0533a00db0b84768891cadc5ce5caac0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2db4457ae9404e52b9104f415ea5f79d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "426e462e3bc94a2683767750433bf600": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "70b2243916fb4e578b2cacb677d898e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_fe4811f016df4305af47091679dd1f9b",
       "max": 20,
       "style": "IPY_MODEL_a0c004929c7e49faa3459777f7c58226"
      }
     },
     "7d7d592764844685b23851b3a5ff8058": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2db4457ae9404e52b9104f415ea5f79d",
       "style": "IPY_MODEL_d369cb34bfe64eb79f73a5c439bb53f3",
       "value": "  0%"
      }
     },
     "9681fcb86f83453e8b8496197e62a888": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9742a48836ae4d2ca0e73201ee7d646b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9a73013e102c4779889bfa863dca4d43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_426e462e3bc94a2683767750433bf600",
       "max": 20,
       "style": "IPY_MODEL_ebf9a411b07e4af49925ffc0cc606660"
      }
     },
     "a0c004929c7e49faa3459777f7c58226": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a2707ba3d2b6460dbc61dc24548ba7a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f22e1bb94d9649b3a97768831444da05",
       "style": "IPY_MODEL_b6011c3a18a44b89bb8f3d9b1a12b489",
       "value": "  0%"
      }
     },
     "ab11f7fd67964c989688ff41cc79e3b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b2e99f829c1b470b8a2f584c3afaf94e",
       "style": "IPY_MODEL_0533a00db0b84768891cadc5ce5caac0",
       "value": " 0/20 [00:00&lt;?, ?it/s]"
      }
     },
     "ac9225ed8f9449f093a14b216d7128e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b2e99f829c1b470b8a2f584c3afaf94e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b5456caa1de8480eab63f118fda7fd6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_7d7d592764844685b23851b3a5ff8058",
        "IPY_MODEL_70b2243916fb4e578b2cacb677d898e5",
        "IPY_MODEL_c9ec663ca42d491da4d7add0e8115bfd"
       ],
       "layout": "IPY_MODEL_9742a48836ae4d2ca0e73201ee7d646b"
      }
     },
     "b6011c3a18a44b89bb8f3d9b1a12b489": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "bc547e9be5e54eb58e159c17ede6f866": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a2707ba3d2b6460dbc61dc24548ba7a6",
        "IPY_MODEL_9a73013e102c4779889bfa863dca4d43",
        "IPY_MODEL_ab11f7fd67964c989688ff41cc79e3b4"
       ],
       "layout": "IPY_MODEL_9681fcb86f83453e8b8496197e62a888"
      }
     },
     "c9ec663ca42d491da4d7add0e8115bfd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d4c39764b0f4462ba85516b9179a4732",
       "style": "IPY_MODEL_ac9225ed8f9449f093a14b216d7128e2",
       "value": " 0/20 [00:00&lt;?, ?it/s]"
      }
     },
     "d369cb34bfe64eb79f73a5c439bb53f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d4c39764b0f4462ba85516b9179a4732": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ebf9a411b07e4af49925ffc0cc606660": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f22e1bb94d9649b3a97768831444da05": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fe4811f016df4305af47091679dd1f9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
